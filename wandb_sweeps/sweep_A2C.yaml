program: train.py
method: bayes
metric:
  goal: maximize
  name: "win_rate"
parameters:
  num_envs:
    value: 72
  timesteps_per_epoch:
    distribution: q_log_uniform_values
    min: 500000
    max: 1000000
    q: 10000
  # opponent_policy:
  #   values:
  #     - "minimax"
  #     - "random"
  eval_episode_num:
    value: 1000
  learning_rate:
    distribution: log_uniform_values
    min: 5e-5
    max: 5e-3
  illegal_move_reward:
    distribution: uniform
    min: -5
    max: 0
  illegal_move_tolerance:
    distribution: int_uniform
    min: 0
    max: 10
  max_depth:
    # distribution: int_uniform
    # min: 1
    # max: 5
    value: 5
  algorithm:
    value: "A2C"
  selection_mode:
    values:
      - "step"
      - "episode"


command:
  - python
  - ${program}
  - ${args_no_boolean_flags}
  - -op
  - minimax
  - random
  - -pb
  - 0.5
  - 0.5


